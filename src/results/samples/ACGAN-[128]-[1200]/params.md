# Core Parameters used within this project

    - python train.py -i 1200 -b 128 -G 1

    - 1.2k iterations, although this was passed multiple times due to mode
        collapse Meaning 3 reruns from epoch 350 were made. Model kept collapsing

    - Batch size of 128 provides better results than all other given batch size

    - In this model the generator has been parsed another layer
